# Python Tutorial RAG System ğŸ

A **Retrieval-Augmented Generation (RAG)** system built with LangChain that answers questions about Python programming using the official Python Tutorial documentation. Features sentence-aware chunking, multiple embedding providers, and both CLI and modern web interfaces.

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.3.0+-green.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-API-orange.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-Web%20UI-red.svg)

## âœ¨ Features

- **ğŸ§  Smart Document Processing**: Sentence-aware text chunking preserves code blocks and context
- **ğŸ” Advanced Retrieval**: ChromaDB vector store with MMR (Maximal Marginal Relevance) search
- **ğŸŒ Multiple Providers**: Support for OpenAI, HuggingFace, and custom embedding models
- **ğŸ’¬ Dual Interfaces**: Modern Streamlit web UI + CLI chat interface
- **ğŸ“š Rich Context**: Processes 16+ Python tutorial HTML files with metadata preservation
- **âš¡ Caching & Performance**: Streamlit caching for instant responses
- **ğŸ› ï¸ Flexible Configuration**: Environment-based config for easy provider switching

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HTML Docs     â”‚â”€â”€â”€â–¶â”‚     Loader      â”‚â”€â”€â”€â–¶â”‚    Chunker      â”‚
â”‚  (py_tutorial)  â”‚    â”‚  (BeautifulSoup)â”‚    â”‚ (Sentence-aware)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web/CLI UI    â”‚â—€â”€â”€â”€â”‚   RAG Chain     â”‚â—€â”€â”€â”€â”‚   Embeddings    â”‚
â”‚   (Streamlit)   â”‚    â”‚  (LangChain)    â”‚    â”‚   (OpenAI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Retriever     â”‚â—€â”€â”€â”€â”‚  Vector Store   â”‚
                       â”‚     (MMR)       â”‚    â”‚   (ChromaDB)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+ 
- OpenAI API key (or HuggingFace/custom provider)
- Git (for cloning)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/zeinabwehbe/python-tutorial-rag.git
   cd python-tutorial-rag
   ```

2. **Set up virtual environment**
   ```bash
   python -m venv .venv
   
   # Windows
   .\.venv\Scripts\activate
   
   # macOS/Linux
   source .venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   # Copy and edit .env file
   cp .env.example .env
   ```
   
   Add your API keys to `.env`:
   ```env
   OPENAI_API_KEY=your-openai-api-key-here
   EMBEDDING_PROVIDER=openai
   LLM_PROVIDER=openai
   ```

5. **Download NLTK data** (for sentence chunking)
   ```bash
   python -c "import nltk; nltk.download('punkt_tab')"
   ```

### Usage

#### ğŸŒ Web Interface (Recommended)
```bash
streamlit run src/web_app.py
```

Then open http://localhost:8501 in your browser.

#### ğŸ’» CLI Interface
```bash
python -m src.app
```

#### ğŸ”§ Manual Ingestion (if needed)
```bash
python -c "from src.app import ingest; ingest()"
```

## ğŸ“– Example Questions

Try asking these questions to test the system:

- *"What are list comprehensions in Python?"*
- *"How do I handle exceptions and errors?"*
- *"Explain Python's for loops with examples"*
- *"What is the difference between lists and tuples?"*
- *"How do I create and use functions in Python?"*
- *"What are Python modules and how do I import them?"*

## âš™ï¸ Configuration

Key settings in `.env`:

| Variable | Description | Options |
|----------|-------------|---------|
| `EMBEDDING_PROVIDER` | Embedding model provider | `openai`, `huggingface`, `deepseek` |
| `EMBEDDING_MODEL` | Specific model name | `text-embedding-3-small`, etc. |
| `LLM_PROVIDER` | Language model provider | `openai`, `local` |
| `LLM_MODEL` | Specific LLM model | `gpt-4o-mini`, `gpt-3.5-turbo`, etc. |
| `CHUNK_SIZE` | Maximum characters per chunk | `1000` (default) |
| `OVERLAP_SENTENCES` | Sentence overlap between chunks | `2` (default) |
| `RETRIEVER_K` | Number of chunks to retrieve | `5` (default) |

## ğŸ“ Project Structure

```
python-tutorial-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ loader.py          # HTML document parsing
â”‚   â”œâ”€â”€ chunker.py         # Sentence-aware text chunking
â”‚   â”œâ”€â”€ embedder.py        # Multi-provider embeddings
â”‚   â”œâ”€â”€ retriever.py       # ChromaDB retrieval setup
â”‚   â”œâ”€â”€ chain.py           # RAG chain with LangChain
â”‚   â”œâ”€â”€ app.py             # CLI interface
â”‚   â””â”€â”€ web_app.py         # Streamlit web interface
â”œâ”€â”€ py_tutorial/           # Python tutorial HTML files
â”œâ”€â”€ vectorstore/           # ChromaDB persistence (auto-created)
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ PROJECT_PLAN.md        # Development roadmap
â””â”€â”€ README.md             # This file
```

## ğŸ§ª Development

### Running Tests
```bash
# Test individual components
python -c "from src.loader import load_documents; print(f'Loaded {len(load_documents())} documents')"
python -c "from src.chunker import chunk_documents; from src.loader import load_documents; chunks = chunk_documents(load_documents()); print(f'Created {len(chunks)} chunks')"
```

### Adding New Document Sources
1. Place HTML files in `py_tutorial/` directory
2. Modify `src/loader.py` if different parsing logic needed
3. Run ingestion: `python -c "from src.app import ingest; ingest()"`

### Switching Embedding Providers

**OpenAI** (recommended):
```env
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
OPENAI_API_KEY=your-key
```

**HuggingFace** (free, local):
```env
EMBEDDING_PROVIDER=huggingface
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

**Custom providers**: Extend `src/embedder.py`

## ğŸ› Troubleshooting

### Common Issues

**ModuleNotFoundError: No module named 'src'**
- Ensure you're running from the project root directory
- For Streamlit: Fixed automatically with `sys.path` setup in `web_app.py`

**OpenAI quota exceeded**
- Switch to HuggingFace provider temporarily
- Check your OpenAI billing and usage limits

**No vectorstore found**
- Run ingestion manually: `python -c "from src.app import ingest; ingest()"`
- Check that `py_tutorial/` contains HTML files

**Slow embedding performance**
- Use OpenAI for faster cloud embeddings
- For local: ensure CUDA GPU support for sentence-transformers

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Python Software Foundation** for the excellent Python Tutorial documentation
- **LangChain** for the RAG framework
- **ChromaDB** for vector storage
- **OpenAI** for embeddings and language models
- **Streamlit** for the web interface framework

## ğŸ“Š Performance Stats

- **Documents**: 16 Python tutorial HTML files
- **Chunks**: 304 sentence-aware chunks (avg ~991 characters)
- **Embedding Model**: OpenAI `text-embedding-3-small` (1536 dimensions)
- **Response Time**: <2 seconds for most queries
- **Retrieval**: Top-5 MMR search for optimal relevance/diversity

---

**Built with â¤ï¸ for Python learners everywhere!**